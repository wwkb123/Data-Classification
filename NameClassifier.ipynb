{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "with open('test.txt', 'r') as f:\n",
    "    sample = f.read()\n",
    "\n",
    "\n",
    "    \n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Play', 'Ivanka', 'Schnall', 'Lois Winston', 'Vanessa Trump', 'Donald Trump', 'Manhattan', 'New York', 'Boston', 'Vanessa', 'Trump Jr', 'Secret Service', 'Michael Cohen', 'David Schnall', 'NBC News', 'NYPD', 'Donald', 'Trump'}\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(sample)  #each line as an element in the list\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences] #each word in the sentence as an element\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences] #tag each word\n",
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':  #Name Entity\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "\n",
    "    return entity_names\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    # Print results per sentence\n",
    "    # print extract_entity_names(tree)\n",
    "\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print all entity names\n",
    "#print entity_names\n",
    "\n",
    "# Print unique entity names\n",
    "print (set(entity_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "firstname = []\n",
    "lastname = []\n",
    "fullname = []\n",
    "\n",
    "f1 = open(\"firstname.csv\",\"r\")\n",
    "reader1 = csv.reader(f1)\n",
    "for row in reader1:\n",
    "    for word in row:\n",
    "        firstname.append(word)\n",
    "        \n",
    "f2 = open(\"lastname.csv\",\"r\")\n",
    "reader2 = csv.reader(f2)\n",
    "for row in reader2:\n",
    "    for word in row:\n",
    "        lastname.append(word)\n",
    "\n",
    "\n",
    "    \n",
    "for x in range(0,1000):\n",
    "    random.seed(x)\n",
    "    first = random.randint(1,5494)\n",
    "    last = random.randint(1,88799)\n",
    "    fullname.append(firstname[first]+\" \"+lastname[last])\n",
    "    #print(firstname[first],lastname[last])\n",
    "#print(fullname)\n",
    "\n",
    "f3 = open(\"patientdata.txt\",\"r\")\n",
    "f4 = open(\"output.txt\",\"w\")\n",
    "recordList = f3.readlines()\n",
    "for x in range(0,1000):\n",
    "    line = fullname[x]+\"\\t\"+recordList[x]\n",
    "    f4.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dominica Holian', 'Arline Lechelt', 'Benjamin Sofranko', 'Billie Juliusson', 'Elaina Cosgriff', 'Rosendo Turtura', 'Odette Broden', 'Kelley Lauderbaugh', 'Ross Ekis', 'Lewis Anawaty', 'Cheyenne Grass', 'Arnita Lepisto', 'Johnathan Meua', 'Howard Alger', 'Shantel Freeney', 'Rick Dwelle', 'Alex Interiano', 'Gina Merrit', 'Magaly Dingle', 'Herbert Brandis', 'Bonnie Krampe', 'Franklyn Hershkop', 'Twanda Essen', 'Sirena Waughtel', 'Tommie Magnano', 'Lottie Feather', 'Micheal Dille', 'George Mang', 'Lanora', 'Broich', 'Jimmie Falor', 'Karima Purser', 'Belia Kourkoumellis', 'Annette', 'Glynda Escandon', 'Leeanna Brandon', 'Linnie Wingeier', 'Johnetta Pocklington', 'Renda Rouzer', 'Ursula Pinna', 'Sherie Edgley', 'Tomasa Zehner', 'Cristina Burum', 'Cordie', 'Bobbye Quall', 'White Single', 'Tomeka Kaaua', 'Corrie Genzone', 'American Unknown', 'Bernie Rozo', 'Danille Dade', 'Francoise', 'Harrison Hemken', 'Davida Pasquale', 'Arminda Zarrillo', 'Nadine Pieper', 'Rossana Laney', 'Samantha Muhlhauser', 'Regina', 'Jerlene Fiorentini', 'Khalilah Witsell', 'Barney Coscia', 'Shayne Rung', 'Augustina Boggi', 'Karolyn Mcnurlen', 'American Married', 'Tianna Breach', 'Michelina Zitzloff', 'Billy Feehery', 'Rosendo Griffard', 'Branden Pytlewski', 'Francisco Cesare', 'Renae Rossini', 'Israel Waitz', 'Leonarda Eans', 'Lanora Ailstock', 'Barrie Spella', 'Glinda Fruchter', 'Henry Kratt', 'Arielle Badeau', 'Carissa Sulley', 'Raquel', 'Randy Saviano', 'Brant Bevans', 'Odessa Hildinger', 'Kelley Tauteoli', 'Cheryl Childres', 'Marcia Rouff', 'Reina Moccia', 'Female', 'Julian Medaries', 'White', 'Lottie Barmettler', 'Arnita Luquette', 'Steffanie Dunsmore', 'Jovan', 'Serita Amend', 'Alanna Brustmann', 'Wilbur', 'White Unknown', 'Lucinda Bistodeau', 'Dortha Devoe', 'Annmarie Colley', 'Celina Calais', 'Eldora Spruiell', 'Kelley Woyahn', 'Luciano Denenberg', 'Chelsie Frezza', 'Edward Lites', 'Sammie Ignoria', 'Bridgett Escobar', 'Stewart Zagen', 'Aletha Philben', 'Latrina Paciolla', 'Malcolm Kill', 'Catalina Rangasammy', 'Terry Rabkin', 'Asian Unknown', 'Margert Reinoso', 'Lorena Dziuban', 'Denise Ancell', 'Daniela Normann', 'Kathrin Bonugli', 'Brinda Harralson', 'Darcie Zaharis', 'Wilton', 'Bonnie Wieberg', 'Katelyn Bockelmann', 'Michell Manchini', 'Malisa Poland', 'Bulah School', 'Buford Gappa', 'Benito Candle', 'Britni Swihart', 'White Divorced', 'Jeannine Burgraff', 'Taneka Oberhelman', 'Idalia Tamas', 'Quinton Wheeless', 'Sanford Violett', 'Robert Hushon', 'Annelle Houze', 'Kermit Helmsing', 'Giuseppina', 'Chung Cumba', 'Terry Hietala', 'Rina Rosa', 'Roseann Antonio', 'Tommie Rathbone', 'Fermin', 'Name \\ufeffPatientID', 'Alyson Cracchiolo', 'Amina Wasco', 'Miriam Eschmann', 'Burian', 'Lilia Aldo', 'Felton Halik', 'Jackie Columbus', 'Silvia', 'Cherry Tresca', 'Cathie Applewhite', 'Rosalva', 'Aretha Ilse', 'Palmer Suthoff', 'Denae Murakawa', 'David Buckland', 'American Separated', 'Edward', 'Alycia Briola', 'Lorita Scarboro', 'Sarita Heckler', 'Brittny Coleman', 'Asian Married', 'Brian Erichson', 'White Married', 'Lonnie Soderquist', 'Otilia Suns', 'Garth Macinnis', 'Danyelle Deponte', 'Basilia Vandebogart', 'Annie Poock', 'Roland', 'Tamika Hussong', 'Dreama Ehlen', 'Aleshia Kinseth', 'Frank Salzar', 'Shante Liquori', 'Alesha Wachter', 'Evalyn League', 'American Widowed', 'Lanora Glader', 'Reina Kassouf', 'Mason Frayser', 'Jammie Corridan', 'Richard Sherlock', 'Lynelle Arman', 'Delmar Metter', 'Regina Mehtala', 'Alisia Zaucha', 'Elvira Sochan', 'Anissa Whiteside', 'Male', 'Michelle Garraway', 'Shante Leyden', 'Rudolf Collea', 'Johnna Pochiba', 'Luella Kubasik', 'Blanca', 'Zina Citrano', 'Sarafian', 'American Single', 'Jamila Reidling', 'Floria Gilleland', 'Millie Zange', 'Andres Andrepont', 'Cythia Viscia', 'Asian Widowed', 'Marica Landmann', 'Allison Worlds', 'Machelle Vegter', 'Cecille Rangel', 'Vashti Bennard', 'Joanie Ammar', 'Norine Montavon', 'Ivana Stine', 'Clementina Jerrell', 'Kina Streeby', 'Alissa Freimark', 'Asian Divorced', 'Creola Brookhouse', 'Shackleton', 'Sabrina', 'Estelle Winnett', 'Hattie Upadhyaya', 'Karrie Detraglia', 'Tomasa', 'Sabrina Lagrotta', 'Terrell Radwan', 'Alexis Boid', 'Caroll Fansler', 'Jennie Reddish', 'Alysha Heenan', 'Oralee Escue', 'Brazelton', 'Lillian Wann', 'Jonathon Schmoldt', 'American Divorced', 'Annabell Grullon', 'Adelaida Cannard', 'Anjelica Finneran', 'Linnie Tattrie', 'Jacquline Algarin', 'Russell Esser', 'Samatha Bowker', 'Benjamin Hepperly', 'Douglas Rayborn', 'Dani Shappard', 'Davina Abes', 'Derick', 'Rosaline Cochis', 'Ashton Frankenreiter', 'Cordie Pflanz', 'Cordie Askren', 'Mireille Arroyano', 'Catalina Belarmino', 'Jarrett Akinyooye', 'Brandon Schink', 'Rosia Woolever', 'Bobian', 'Arcelia Carothers', 'Asian Single', 'Stephen Lemay', 'Rabern', 'Carlos Reder', 'Halley Tufts', 'Virgina Balletta', 'Alena Drevs', 'Brittni Dupler', 'Luanna Palazzi', 'Barbera Higaneda', 'Nereida Paulin', 'Nettie Piepenburg', 'Corene Askey', 'Emerson Nanthanong', 'Ashlea Mackay', 'Ashlee Unnold', 'Jamaal Serville', 'Eustolia', 'Shelton Petite', 'Wesley Brester', 'Carson Bellinghausen', 'Nickie Winett', 'Beryl Routzen', 'Sabrina Dingee', 'Jessenia Burghard', 'Bernard Kalua', 'Keisha Baillio', 'Marlyn Lally', 'Cherelle Gracey', 'Unknown', 'Hermina', 'Vern Cratch', 'Sara Lerma', 'Andrew Orebaugh', 'Shanelle Selakovic', 'Eneida Tzeremes', 'Eli', 'Lewis Poston', 'Linsey Shawver', 'American', 'Mahalia Zomer', 'Kenneth Hagele', 'Micheline Allinder', 'African', 'Frankie Nettles', 'Geri Lubic', 'Freeda Nicewonger', 'Tashina Klingler', 'Karlyn Belmore', 'Irmgard Korona', 'Madalyn Limas', 'Cameron Neiswonger', 'Bryanna Foxe', 'Asian Separated', 'Jamila Golan', 'Ashlie Mandujano', 'Vickey Martinkus', 'Arianne Wykle', 'Stevie Sapnu', 'Werner', 'Ivonne Mcelmury', 'Benita Loretz', 'Annika Wehe', 'Merlyn Licea', 'Rosaria Iwasa', 'Cherish Cantave', 'William Germon', 'Bernie Schoeneck', 'Blanch Rebuldela', 'Geraldine Hample', 'Halley Shockley', 'Johana Zak', 'Mignon Mccabe', 'Brigette Pettitt', 'Shayna Barke', 'Milagro Stefanski', 'Jasper Entrekin', 'Rolland Sipriano', 'Adelina Yedinak', 'Fidela'}\n"
     ]
    }
   ],
   "source": [
    "f5 = open(\"output.txt\")\n",
    "data = f5.read()\n",
    "sentences = nltk.sent_tokenize(data)  #each line as an element in the list\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences] #each word in the sentence as an element\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences] #tag each word\n",
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':  #Name Entity\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "\n",
    "    return entity_names\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    # Print results per sentence\n",
    "    # print extract_entity_names(tree)\n",
    "\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print all entity names\n",
    "#print entity_names\n",
    "\n",
    "# Print unique entity names\n",
    "print (set(entity_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
